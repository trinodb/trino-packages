connector.name=ai
ai.provider=openai
# llama3.2 is the small and fast so you can use it for testing on a local machine
ai.model=llama3.2
ai.openai.endpoint=http://localhost:11434
ai.openai.api-key=none
